{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import sys\n",
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "from rank_bm25 import BM25Okapi\n",
    "from nltk.tokenize import word_tokenize\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import torch\n",
    "\n",
    "#Use the BM25 algorithm to find the most relevant table based on the query tokens and the corpus.\n",
    "def bm25_retrieve_relevant_table(query, corpus,list_tables_info,actual_table_info,top_k_list):\n",
    "    query_tokens = word_tokenize(query)\n",
    "    corpus_tokenize = [word_tokenize(table) for table in corpus]\n",
    "\n",
    "    bm25 = BM25Okapi(corpus_tokenize)\n",
    "    scores = bm25.get_scores(query_tokens)\n",
    "\n",
    "    # Get indices of top-k most relevant tables\n",
    "    top_k_indices = sorted(range(len(scores)), key=lambda i: scores[i], reverse=True)[:max(top_k_list)]\n",
    "    top_k_tables = [list_tables_info[i] for i in top_k_indices]\n",
    "\n",
    "    # Check if actual_table_info is in any of the top-k lists\n",
    "    results = {k: actual_table_info in top_k_tables[:k] for k in top_k_list}\n",
    "    return results\n",
    "\n",
    "# Download NLTK tokenizer data if not already available\n",
    "nltk.download('punkt')\n",
    "nltk.download('punkt_tab')\n",
    "def preprocess(text):\n",
    "    \"\"\"Tokenize and preprocess text.\"\"\"\n",
    "    return word_tokenize(text.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def table_to_text(table):\n",
    "    \"\"\"\n",
    "    Converts a table (list of lists) to a string.\n",
    "    Each row is concatenated with spaces, and rows are joined with newlines.\n",
    "    \"\"\"\n",
    "    return \" \".join([\" \".join(map(str, row)) for row in table])\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    result = []\n",
    "    for k in [50,100,200,500]:\n",
    "        totto_retrieval_dataset_path = f\"./data/retrieval_data/totto_retrieval_{k}.json\" \n",
    "        top_k_list = [1, 5, 10, 15, 20]\n",
    "        # Open and read the JSON file\n",
    "        #with open(wtq_dataset_path, 'r') as file:\n",
    "        #    data = json.load(file)\n",
    "\n",
    "        \n",
    "        data = []\n",
    "        with open(totto_retrieval_dataset_path, 'r') as file:\n",
    "            data = json.load(file)\n",
    "        print(\"total tables: \", len(data))\n",
    "        for idx, data_point in enumerate(data):\n",
    "            # Prepare the query text\n",
    "            query_text = f\"{data_point['summary']}\".lower()\n",
    "            if idx % 50 == 0:\n",
    "                print(f\"{idx}\", flush=True)\n",
    "                \n",
    "            for table_info in [\"title_tab-description\",\"title_column_header\", \"title_col_table\",\"exact_row\"]:\n",
    "                actual_table_info, list_all_table_info = data_point[f\"list_{table_info}_retrieval\"] \n",
    "                corpus = [table.lower() for table in list_all_table_info]\n",
    "                bm25_top_k_found_it = bm25_retrieve_relevant_table(query_text, corpus,list_all_table_info,actual_table_info,top_k_list) \n",
    "                # dpr_top_k_found_it = dpr_retrieve_relevant_table(query_text, corpus,list_all_table_info,actual_table_info,top_k_list)  \n",
    "                \n",
    "                for top_k in top_k_list: \n",
    "                    result.append({\"idx\":idx,\n",
    "                                \"top_k\":top_k,\n",
    "                                \"table_info\":table_info , \n",
    "                                \"bm_25\":bm25_top_k_found_it[top_k],\n",
    "                                # \"dpr\":dpr_top_k_found_it[top_k]\n",
    "                                })\n",
    "                if idx % 50 == 0:\n",
    "                    print(f\"\\t{table_info}: BM: {bm25_top_k_found_it}\", flush=True)\n",
    "                    if table_info == \"exact_row\": \n",
    "                        df = pd.DataFrame(result)\n",
    "                        print(df[\"bm_25\"].mean())\n",
    "                        df.to_csv(f'./results/results_{k}.csv',index=False)\n",
    "                        del df \n",
    "        df = pd.DataFrame(result)\n",
    "        print(df[\"bm_25\"].mean())\n",
    "        df.to_csv(f'./results/results_{k}.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "colbert",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
